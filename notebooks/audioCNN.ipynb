{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QB4FbtizrjWP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "DEAM_PATH = \"/content/drive/MyDrive/DEAM\"\n",
        "AUDIO_DIR = f\"{DEAM_PATH}/Audio\"\n",
        "MEL_DIR   = f\"{DEAM_PATH}/MEL\"\n",
        "os.makedirs(MEL_DIR, exist_ok=True)\n",
        "SR = 22050\n",
        "N_MELS = 128\n",
        "WINDOW_SEC = 20\n",
        "HOP_SEC = 10\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 5\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#audio augmentation\n",
        "\n",
        "def augment_audio(y, sr):\n",
        "    if random.random() < 0.5:\n",
        "        rate = random.uniform(0.9, 1.1)\n",
        "        y = librosa.effects.time_stretch(y=y, rate=rate)\n",
        "\n",
        "    if random.random() < 0.5:\n",
        "        n_steps = random.randint(-2, 2)\n",
        "        y = librosa.effects.pitch_shift(y=y, sr=sr, n_steps=n_steps)\n",
        "\n",
        "    return y"
      ],
      "metadata": {
        "id": "Y-lDjIvLFdar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature extraction\n",
        "\n",
        "def mel_spectrogram(y):\n",
        "    mel = librosa.feature.melspectrogram(\n",
        "        y=y,\n",
        "        sr=SR,\n",
        "        n_mels=N_MELS,\n",
        "        fmax=8000\n",
        "    )\n",
        "    mel = librosa.power_to_db(mel)\n",
        "    return mel.astype(np.float32)\n",
        "\n",
        "for f in tqdm(os.listdir(AUDIO_DIR)):\n",
        "    if not f.endswith(\".mp3\"):\n",
        "        continue\n",
        "\n",
        "    match = re.match(r\"(\\d+)\", f)\n",
        "    if not match:\n",
        "        print(f\"Skipping {f}\")\n",
        "        continue\n",
        "    song_id = int(match.group(1))\n",
        "\n",
        "    path = os.path.join(AUDIO_DIR, f)\n",
        "    y, sr = librosa.load(path, sr=SR)\n",
        "\n",
        "    win = int(WINDOW_SEC * SR)\n",
        "    hop = int(HOP_SEC * SR)\n",
        "\n",
        "    segments = []\n",
        "    for start in range(0, len(y) - win + 1, hop):\n",
        "        seg = y[start:start+win]\n",
        "        mel = mel_spectrogram(seg)\n",
        "        segments.append(mel)\n",
        "\n",
        "    if len(segments) == 0:\n",
        "        continue\n",
        "\n",
        "    segments = np.stack(segments)\n",
        "    np.save(os.path.join(MEL_DIR, f\"{song_id}.npy\"), segments)\n"
      ],
      "metadata": {
        "id": "Uke6MgOJ0gvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeff2d7b-2f15-44b5-dc8c-4bfa693c723b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1809/1809 [13:43<00:00,  2.20it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset\n",
        "\n",
        "class MusicDataset(Dataset):\n",
        "    def __init__(self, df, mel_dir, augment=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.mel_dir = mel_dir\n",
        "        self.augment = augment\n",
        "        self.samples = []\n",
        "\n",
        "        for _, row in self.df.iterrows():\n",
        "            song_id = int(row[\"song_id\"])\n",
        "            mel_path = os.path.join(mel_dir, f\"{song_id}.npy\")\n",
        "            segments = np.load(mel_path)\n",
        "            for mel in segments:\n",
        "                self.samples.append((mel, row[\"label_idx\"]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      mel, label = self.samples[idx]\n",
        "\n",
        "      if self.augment:\n",
        "        mel = mel + np.random.normal(0, 0.01, mel.shape)\n",
        "\n",
        "      mel = torch.tensor(mel, dtype=torch.float32).unsqueeze(0)\n",
        "      label = torch.tensor(label, dtype=torch.long)\n",
        "      return mel, label\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bhGznJV7hD6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "\n",
        "class AudioCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(128, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "a2ZJ_JDVhPfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DEAM_PATH = \"/content/drive/MyDrive/DEAM\"\n",
        "\n",
        "!ls $DEAM_PATH\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsBsXEzWQN6P",
        "outputId": "dc675080-ae2a-48c7-eb31-a20886f10df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Annotations  Audio  MEL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "ann1 = pd.read_csv(f\"{DEAM_PATH}/Annotations/static_annotations_averaged_songs_1_2000.csv\")\n",
        "ann2 = pd.read_csv(f\"{DEAM_PATH}/Annotations/static_annotations_averaged_songs_2000_2058.csv\")\n",
        "annotations = pd.concat([ann1, ann2], ignore_index=True)\n",
        "\n",
        "annotations.columns = annotations.columns.str.strip()\n",
        "\n",
        "\n",
        "\n",
        "song_id = annotations.iloc[0][\"song_id\"]\n",
        "audio_path = f\"{DEAM_PATH}/Audio/{int(song_id)}.mp3\"\n",
        "y, sr = librosa.load(audio_path, sr=22050)\n",
        "print(y.shape, sr)\n",
        "\n",
        "audio_ids = set()\n",
        "for f in os.listdir(f\"{DEAM_PATH}/Audio\"):\n",
        "    match = re.match(r\"^(\\d+)\\.mp3$\", f)\n",
        "    if match:\n",
        "        audio_ids.add(int(match.group(1)))\n",
        "\n",
        "annotations = annotations[annotations[\"song_id\"].astype(int).isin(audio_ids)].reset_index(drop=True)\n",
        "print(f\"Number of usable songs: {len(annotations)}\")\n",
        "\n",
        "y_targets = annotations[[\"valence_mean\", \"arousal_mean\"]].values.astype(np.float32)\n",
        "print(y_targets.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDzoyz-Mhv0T",
        "outputId": "456904ab-d41e-45b9-f3a9-a6bbfd003fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(993595,) 22050\n",
            "Number of usable songs: 1800\n",
            "(1800, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load and split data\n",
        "\n",
        "df = annotations.copy()\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "def mood_from_valence_arousal(valence, arousal, v_thresh=5.0, a_thresh=5.0):\n",
        "    if valence >= v_thresh and arousal >= a_thresh:\n",
        "        return \"happy\"\n",
        "    elif valence < v_thresh and arousal >= a_thresh:\n",
        "        return \"angry\"\n",
        "    elif valence < v_thresh and arousal < a_thresh:\n",
        "        return \"sad\"\n",
        "    else:\n",
        "        return \"relaxed\"\n",
        "\n",
        "df[\"label\"] = df.apply(\n",
        "    lambda r: mood_from_valence_arousal(r[\"valence_mean\"], r[\"arousal_mean\"]),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "label2idx = {label: idx for idx, label in enumerate(df[\"label\"].unique())}\n",
        "idx2label = {idx: label for label, idx in label2idx.items()}\n",
        "df[\"label_idx\"] = df[\"label\"].map(label2idx)\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    df, test_size=0.2, random_state=42, stratify=df[\"label_idx\"]\n",
        ")\n",
        "\n",
        "def collate_fn(batch):\n",
        "    mels, labels = zip(*batch)\n",
        "\n",
        "    max_len = max(mel.shape[2] for mel in mels)\n",
        "    mels_padded = [\n",
        "        torch.nn.functional.pad(mel, (0, max_len - mel.shape[2]))\n",
        "        for mel in mels\n",
        "    ]\n",
        "\n",
        "    mels = torch.stack(mels_padded).float()\n",
        "    labels = torch.stack(labels)\n",
        "\n",
        "    return mels, labels\n",
        "\n",
        "\n",
        "def create_loaders(train_df, val_df, audio_dir):\n",
        "    train_ds = MusicDataset(train_df, audio_dir, augment=False)\n",
        "    val_ds = MusicDataset(val_df, audio_dir, augment=False)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=0\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_ds, batch_size=BATCH_SIZE, collate_fn=collate_fn, num_workers=0\n",
        "    )\n",
        "    return train_loader, val_loader\n",
        "\n",
        "train_loader, val_loader = create_loaders(train_df, val_df, MEL_DIR)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dYHHwCBuhZ_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "\n",
        "model = AudioCNN().to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    train_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
        "\n",
        "    for x, y in train_bar:\n",
        "\n",
        "        x = x.float().to(DEVICE)\n",
        "        y = y.long().to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "        train_bar.set_postfix(\n",
        "            loss=f\"{loss.item():.4f}\",\n",
        "            acc=f\"{correct/total:.3f}\"\n",
        "        )\n",
        "\n",
        "    train_loss = total_loss / len(train_loader)\n",
        "    train_acc = correct / total\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        val_bar = tqdm(val_loader, desc=\"Validation\", leave=False)\n",
        "        for x, y in val_bar:\n",
        "            x = x.float().to(DEVICE)\n",
        "            y = y.long().to(DEVICE)\n",
        "\n",
        "            outputs = model(x)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "\n",
        "            val_correct += (preds == y).sum().item()\n",
        "            val_total += y.size(0)\n",
        "\n",
        "            val_bar.set_postfix(\n",
        "                acc=f\"{val_correct/val_total:.3f}\"\n",
        "            )\n",
        "\n",
        "    val_acc = val_correct / val_total\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch+1} | \"\n",
        "        f\"Train Loss: {train_loss:.4f} | \"\n",
        "        f\"Train Acc: {train_acc:.3f} | \"\n",
        "        f\"Val Acc: {val_acc:.3f}\")\n"
      ],
      "metadata": {
        "id": "DlR6ldHXhj-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12d29868-6dcc-4709-87fb-ea89fdbf5a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 1.1762 | Train Acc: 0.514 | Val Acc: 0.555\n",
            "\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 1.1357 | Train Acc: 0.533 | Val Acc: 0.538\n",
            "\n",
            "Epoch 3/5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 1.1217 | Train Acc: 0.543 | Val Acc: 0.581\n",
            "\n",
            "Epoch 4/5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 1.1161 | Train Acc: 0.544 | Val Acc: 0.559\n",
            "\n",
            "Epoch 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 | Train Loss: 1.0984 | Train Acc: 0.553 | Val Acc: 0.552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    }
  ]
}